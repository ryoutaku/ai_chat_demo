import os
from os.path import join, dirname
from dotenv import load_dotenv

import streamlit as st

import openai
from llama_index import StorageContext, ServiceContext, load_index_from_storage
from llama_index.callbacks import CallbackManager, LlamaDebugHandler
from llama_index.storage.docstore import SimpleDocumentStore
from llama_index.storage.index_store import SimpleIndexStore
from llama_index.vector_stores import SimpleVectorStore

# OpenAIã®APIkeyèª­ã¿è¾¼ã¿
load_dotenv(verbose=True)
dotenv_path = join(dirname(__file__), '.env')
load_dotenv(dotenv_path)
openai.api_key = os.environ.get("OPENAI_API_KEY")

# LlamaIndexã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹èª­ã¿è¾¼ã¿
storage_context = StorageContext.from_defaults(
    docstore=SimpleDocumentStore.from_persist_dir(persist_dir="./storage_context"),
    vector_store=SimpleVectorStore.from_persist_dir(persist_dir="./storage_context"),
    index_store=SimpleIndexStore.from_persist_dir(persist_dir="./storage_context"),
)
llama_debug_handler = LlamaDebugHandler()
callback_manager = CallbackManager([llama_debug_handler])
service_context = ServiceContext.from_defaults(callback_manager=callback_manager)
index = load_index_from_storage(storage_context, service_context=service_context)
query_engine = index.as_query_engine()

# ãƒãƒ£ãƒƒãƒˆç”»é¢ã®å®Ÿè£…
with st.sidebar:
    "[æ ªå¼ä¼šç¤¾ãƒãƒãƒ¼ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰-æ±ºç®—èª¬æ˜è³‡æ–™](https://corp.moneyforward.com/ir/library/presentation/)"
    "ã€è³ªå•ä¾‹ã€‘"
    "ãƒãƒãƒ¼ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã®æ³•äººå‘ã‘ã‚µãƒ¼ãƒ“ã‚¹ã¯ä½•ãŒã‚ã‚‹ã‹ã€‚"
    "æ³•äººå‘ã‘ARPAã«ã¤ã„ã¦ã€SMBã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯QoQã§ãƒ•ãƒ©ãƒƒãƒˆãªã®ã‹ã€‚"
    "ä¸­å …ä¼æ¥­åŠã³ä¸­å°ä¼æ¥­ã®ARPAã¨é¡§å®¢æ•°ã®YoYæˆé•·ç‡ã€ã¾ãŸã¯QoQã®æˆé•·ç‡ã‚’æ•™ãˆã¦ã„ãŸã ããŸã„ã€‚"

st.title("ğŸ’¬ Chatbot")
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ãƒãƒãƒ¼ãƒ•ã‚©ãƒ¯ãƒ¼ãƒ‰ã®2023å¹´11æœˆæœŸã®æ±ºç®—æƒ…å ±ã«ã¤ã„ã¦å›ç­”ã§ãã¾ã™"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

if prompt := st.chat_input():
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.chat_message("user").write(prompt)
    response = query_engine.query(prompt)
    st.session_state.messages.append({"role": "assistant", "content": response.response})
    st.chat_message("assistant").write(response.response)
